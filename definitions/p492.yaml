id: 492
type: PolicyDefinition
metadata:
    policyName: dan.DanInTheWild
    category: ML/AI Scanning
    stage: source
    description: A subset of jailbreaks from the DanInTheWild jailbreak library. Tries a set of known jailbreaks, in an attempt to get a model to disregard alignment/system prompt. Success is measured by not getting a safety mitigation message. The number of prompts in the subset can be configured via the `soft_probe_prompt_cap` run parameter.
    scheduled_policy: false
    scriptId: 475
    variables: ""
    conditionName: ""
    suggestion: ""
